batch_size = 256
stack_size = 1
do_profile = false
num_epochs = 10
regressor = "mace"
task = "e_form"

[data]
shuffle_seed = 1618
train_split = 30
test_split = 3
valid_split = 3
batches_per_group = 0

[cli]
verbosity = "info"
show_progress = true

[device]
device = "gpu"
max_gpus = 1
gpu_ids = [0, 1, 2]

[log]
log_dir = "logs"
logs_per_epoch = 16
epochs_per_ckpt = 10
exp_name = "before-hpo"

[train]
lr_schedule_kind = "cosine"
start_lr_frac = 0.1
base_lr = 1e-3
end_lr_frac = 0.04
weight_decay = 0.001
beta_1 = 0.9
beta_2 = 0.999
nestorov = true
max_grad_norm = 1.0
schedule_free = false
prodigy = false

[mace]
max_ell = 3
# num_interactions = 5
num_interactions = 2
hidden_irreps = "256x0e"
correlation = 3
readout_mlp_irreps = "256x0e"

[train.loss.reg_loss]
loss_delta = 0.015625
use_rmse = false
